import os
#from pymongo import MongoClient
from blockchain_parser.blockchain import Blockchain
import shutil
from elasticsearch import Elasticsearch
import json
import logging

# try:
#     client = MongoClient('localhost',27017)
#     print('Connected to Mongodb')
# except:
#     print("Error in connecting to database")

# Password for the 'elastic' user generated by Elasticsearch
ELASTIC_PASSWORD = "insert password"

# Found in the 'Manage Deployment' page
CLOUD_ID = "insert cloud id"

# Create the client instance
client = Elasticsearch(
    "http://localhost:9200"
    )



client.index(
 index='zeblytics',
 document={
  "TransactionID" : "",
    "outputIndex": "",
     "outputAddress": "",
    "value": "",
    "inputHash": "",
    "inputIndex": ""
  
 })
 
 
# db = client.index
# collection = db.addressData

# For CSV
header = ['TransactionID','outputIndex','outputAddress','Value','inputHash','inputIndex']
data = []
k = ''
addr = ''
index = ''
 
counter = 1

for i in range(3,4):
    #path = '/Users/krina/Library/Application Support/Bitcoin/BATCHES/Batch' + str(i)
    path = '/Users/krina/Library/Application Support/Bitcoin/blocks'
    #print(path)
    blockchain = Blockchain(os.path.expanduser(path))
    for block in blockchain.get_unordered_blocks():
        #print(block.transactions)
        for tx in block.transactions:
            #print(tx.outputs)
            for no, output in enumerate(tx.outputs):
                print(no, output.value)
                print(tx.hash)
            #print(tx)
            for (inTransaction, output, (no,out)) in zip(tx.inputs,tx.outputs, enumerate(tx.outputs)):
                print(dir(output))
                for j in output.addresses:
                    k = j.address[0].address
                    addr = tx.inputs
                    index = inTransaction.transaction_index
                    #print(inTransaction)

            #To store in CSV file
            row = []
            #print(inTransaction)
            #row.append(tx._txid)
            row.append(tx.hash)
            #print(tx.hash)
            row.append(no)
            row.append(output.type)
            row.append(output.value)
            row.append(k)
            row.append(addr)
            row.append(index)
            data.append(row)
            print("tx=%s index=%d type=%s value=%s address=%s input=%s index=%s" % (tx.hash, no, output.type, output.value, k, addr, index))
            
            #Inserting the data in Elasticsearch
            try:
                    
                    client.index(
                    index='zeblytics',
                    document={
                            "TransactionID" : "",
                                "outputIndex": "",
                                "outputAddress": "",
                                "value": "",
                                "inputHash": "",
                                "inputIndex": ""
                            
                            })
                    print("Inserted: " + str(counter))
                    counter = counter + 1
            
            except:
                    print('Insertion Failed!!!')
            
#     shutil.rmtree(path)
# f = collection.find({'outputAddress': '1gAcRAzWh7Lt3qdNyRsxbyisuyBo8EtMp'})
# for i in f:
#     print(i)
